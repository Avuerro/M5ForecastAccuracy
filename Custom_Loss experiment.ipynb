{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WMSSRE - custom loss\n",
    "\n",
    "based on https://www.kaggle.com/sibmike/fast-clear-wrmsse-18ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "\n",
    "## reload scripts before executing them\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset.reduce_memory import reduce_mem_usage\n",
    "\n",
    "\n",
    "from evaluation.wrmss_loss import WRMSSE_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "\n",
    "data_dir = './data/'\n",
    "\n",
    "# Sales quantities:\n",
    "sales = pd.read_csv(data_dir+'sales_train_validation.csv')\n",
    "\n",
    "# Calendar to get week number to join sell prices:\n",
    "calendar = pd.read_csv(data_dir+'calendar.csv')\n",
    "\n",
    "# Sell prices to calculate sales in USD:\n",
    "sell_prices = pd.read_csv(data_dir+'sell_prices.csv')\n",
    "submission_file = pd.read_csv(data_dir + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "## this cell runs 12 mins\n",
    "sales = reduce_mem_usage(sales)\n",
    "calendar = reduce_mem_usage(calendar)\n",
    "sell_prices = reduce_mem_usage(sell_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>sale</th>\n",
       "      <th>d</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sale_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.880859</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id store_id        item_id  sale       d  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     CA_1  HOBBIES_1_001     1  d_1886   \n",
       "1  HOBBIES_1_002_CA_1_validation     CA_1  HOBBIES_1_002     1  d_1886   \n",
       "2  HOBBIES_1_003_CA_1_validation     CA_1  HOBBIES_1_003     0  d_1886   \n",
       "3  HOBBIES_1_004_CA_1_validation     CA_1  HOBBIES_1_004     0  d_1886   \n",
       "4  HOBBIES_1_005_CA_1_validation     CA_1  HOBBIES_1_005     1  d_1886   \n",
       "\n",
       "   sell_price  sale_usd  \n",
       "0    8.257812  8.257812  \n",
       "1    3.970703  3.970703  \n",
       "2    2.970703  0.000000  \n",
       "3    4.640625  0.000000  \n",
       "4    2.880859  2.880859  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with only last 28 days:\n",
    "cols = [\"d_{}\".format(i) for i in range(1914-28, 1914)]\n",
    "data = sales[[\"id\", 'store_id', 'item_id'] + cols]\n",
    "\n",
    "# To long form:\n",
    "data = data.melt(id_vars=[\"id\", 'store_id', 'item_id'], \n",
    "                 var_name=\"d\", value_name=\"sale\")\n",
    "\n",
    "# Add week of year column from 'calendar':\n",
    "data = pd.merge(data, calendar, how = 'left', \n",
    "                left_on = ['d'], right_on = ['d'])\n",
    "\n",
    "data = data[[\"id\", 'store_id', 'item_id', \"sale\", \"d\", \"wm_yr_wk\"]]\n",
    "\n",
    "# Add weekly price from 'sell_prices':\n",
    "data = data.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "data.drop(columns = ['wm_yr_wk'], inplace=True)\n",
    "\n",
    "# Calculate daily sales in USD:\n",
    "data['sale_usd'] = data['sale'] * data['sell_price']\n",
    "data.head()\n",
    "\n",
    "#this part is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840, 30490)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of categories combinations for aggregations as defined in docs:\n",
    "dummies_list = [sales.state_id, sales.store_id, \n",
    "                sales.cat_id, sales.dept_id, \n",
    "                sales.state_id +'_'+ sales.cat_id, sales.state_id +'_'+ sales.dept_id,\n",
    "                sales.store_id +'_'+ sales.cat_id, sales.store_id +'_'+ sales.dept_id, \n",
    "                sales.item_id, sales.state_id +'_'+ sales.item_id, sales.id]\n",
    "\n",
    "\n",
    "## First element Level_0 aggregation 'all_sales':\n",
    "dummies_df_list =[pd.DataFrame(np.ones(sales.shape[0]).astype(np.int8), \n",
    "                               index=sales.index, columns=['all']).T]\n",
    "\n",
    "# List of dummy dataframes:\n",
    "for i, cats in enumerate(dummies_list):\n",
    "    dummies_df_list +=[pd.get_dummies(cats, drop_first=False, dtype=np.int8).T]\n",
    "    \n",
    "# Concat dummy dataframes in one go:\n",
    "## Level is constructed for free.\n",
    "roll_mat_df = pd.concat(dummies_df_list, keys=list(range(12)), \n",
    "                        names=['level','id'])#.astype(np.int8, copy=False)\n",
    "\n",
    "# Save values as sparse matrix & save index for future reference:\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "roll_mat_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump roll matrix to pickle:\n",
    "roll_mat_df.to_pickle('roll_mat_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free some momory:\n",
    "del dummies_df_list, roll_mat_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to calculate S weights:\n",
    "def get_s(drop_days=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    drop_days: int, equals 0 by default, so S is calculated on all data.\n",
    "               If equals 28, last 28 days won't be used in calculating S.\n",
    "    \"\"\"\n",
    "    # Rollup sales:\n",
    "    d_name = ['d_' + str(i+1) for i in range(1913-drop_days)]\n",
    "    sales_train_val = roll_mat_csr * sales[d_name].values\n",
    "\n",
    "    no_sales = np.cumsum(sales_train_val, axis=1) == 0\n",
    "    sales_train_val = np.where(no_sales, np.nan, sales_train_val)\n",
    "\n",
    "    # Denominator of RMSSE / RMSSE\n",
    "    weight1 = np.nanmean(np.diff(sales_train_val,axis=1)**2,axis=1)\n",
    "    \n",
    "    return weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = get_s(drop_days=0)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functinon to calculate weights:\n",
    "def get_w(sale_usd):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Calculate the total sales in USD for each item id:\n",
    "    total_sales_usd = sale_usd.groupby(\n",
    "        ['id'], sort=False)['sale_usd'].apply(np.sum).values\n",
    "    \n",
    "    # Roll up total sales by ids to higher levels:\n",
    "    weight2 = roll_mat_csr * total_sales_usd\n",
    "    \n",
    "    return 12*weight2/np.sum(weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_w(data[['id','sale_usd']])\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>CA</th>\n",
       "      <td>Level2</td>\n",
       "      <td>CA</td>\n",
       "      <td>X</td>\n",
       "      <td>0.442371</td>\n",
       "      <td>0.442370</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>HOBBIES</th>\n",
       "      <td>Level4</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>X</td>\n",
       "      <td>0.128079</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD</th>\n",
       "      <td>Level4</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>X</td>\n",
       "      <td>0.303335</td>\n",
       "      <td>0.303330</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>FOODS_1</th>\n",
       "      <td>Level5</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.062625</td>\n",
       "      <td>0.062623</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_2</th>\n",
       "      <td>Level5</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>X</td>\n",
       "      <td>0.154642</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1</th>\n",
       "      <td>Level5</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.122088</td>\n",
       "      <td>0.122084</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_1</th>\n",
       "      <td>Level5</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>X</td>\n",
       "      <td>0.229594</td>\n",
       "      <td>0.229592</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2</th>\n",
       "      <td>Level5</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>X</td>\n",
       "      <td>0.073741</td>\n",
       "      <td>0.073738</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th>CA_HOBBIES</th>\n",
       "      <td>Level6</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0.058855</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOUSEHOLD</th>\n",
       "      <td>Level6</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.142772</td>\n",
       "      <td>0.142769</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_HOUSEHOLD</th>\n",
       "      <td>Level6</td>\n",
       "      <td>TX</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.086419</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_HOBBIES</th>\n",
       "      <td>Level6</td>\n",
       "      <td>WI</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>0.027930</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">6</th>\n",
       "      <th>CA_FOODS_2</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.057655</td>\n",
       "      <td>0.057654</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOBBIES_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>0.056463</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOUSEHOLD_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>0.104862</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_HOUSEHOLD_2</th>\n",
       "      <td>Level7</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>0.037909</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_FOODS_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>TX</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.016015</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_FOODS_2</th>\n",
       "      <td>Level7</td>\n",
       "      <td>WI</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.062561</td>\n",
       "      <td>0.062560</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_HOBBIES_1</th>\n",
       "      <td>Level7</td>\n",
       "      <td>WI</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>0.026375</td>\n",
       "      <td>0.026374</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>CA_2_HOUSEHOLD</th>\n",
       "      <td>Level8</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.037630</td>\n",
       "      <td>0.037629</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3_HOUSEHOLD</th>\n",
       "      <td>Level8</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.055869</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>WI_2_FOODS_2</th>\n",
       "      <td>Level9</td>\n",
       "      <td>WI_2</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.030534</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
       "      <th>FOODS_2_029</th>\n",
       "      <td>Level10</td>\n",
       "      <td>FOODS_2_029</td>\n",
       "      <td>X</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_2_183</th>\n",
       "      <td>Level10</td>\n",
       "      <td>FOODS_2_183</td>\n",
       "      <td>X</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_586</th>\n",
       "      <td>Level10</td>\n",
       "      <td>FOODS_3_586</td>\n",
       "      <td>X</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Level_id  Agg_Level_1  Agg_Level_2    Weight  Predicted  \\\n",
       "level id                                                                       \n",
       "1     CA               Level2           CA            X  0.442371   0.442370   \n",
       "3     HOBBIES          Level4      HOBBIES            X  0.128079   0.128075   \n",
       "      HOUSEHOLD        Level4    HOUSEHOLD            X  0.303335   0.303330   \n",
       "4     FOODS_1          Level5      FOODS_1            X  0.062625   0.062623   \n",
       "      FOODS_2          Level5      FOODS_2            X  0.154642   0.154639   \n",
       "      HOBBIES_1        Level5    HOBBIES_1            X  0.122088   0.122084   \n",
       "      HOUSEHOLD_1      Level5  HOUSEHOLD_1            X  0.229594   0.229592   \n",
       "      HOUSEHOLD_2      Level5  HOUSEHOLD_2            X  0.073741   0.073738   \n",
       "5     CA_HOBBIES       Level6           CA      HOBBIES  0.058855   0.058852   \n",
       "      CA_HOUSEHOLD     Level6           CA    HOUSEHOLD  0.142772   0.142769   \n",
       "      TX_HOUSEHOLD     Level6           TX    HOUSEHOLD  0.086420   0.086419   \n",
       "      WI_HOBBIES       Level6           WI      HOBBIES  0.027931   0.027930   \n",
       "6     CA_FOODS_2       Level7           CA      FOODS_2  0.057655   0.057654   \n",
       "      CA_HOBBIES_1     Level7           CA    HOBBIES_1  0.056463   0.056460   \n",
       "      CA_HOUSEHOLD_1   Level7           CA  HOUSEHOLD_1  0.104863   0.104862   \n",
       "      CA_HOUSEHOLD_2   Level7           CA  HOUSEHOLD_2  0.037909   0.037907   \n",
       "      TX_FOODS_1       Level7           TX      FOODS_1  0.016016   0.016015   \n",
       "      WI_FOODS_2       Level7           WI      FOODS_2  0.062561   0.062560   \n",
       "      WI_HOBBIES_1     Level7           WI    HOBBIES_1  0.026375   0.026374   \n",
       "7     CA_2_HOUSEHOLD   Level8         CA_2    HOUSEHOLD  0.037630   0.037629   \n",
       "      CA_3_HOUSEHOLD   Level8         CA_3    HOUSEHOLD  0.055870   0.055869   \n",
       "8     WI_2_FOODS_2     Level9         WI_2      FOODS_2  0.030535   0.030534   \n",
       "9     FOODS_2_029     Level10  FOODS_2_029            X  0.002862   0.002861   \n",
       "      FOODS_2_183     Level10  FOODS_2_183            X  0.002679   0.002677   \n",
       "      FOODS_3_586     Level10  FOODS_3_586            X  0.005074   0.005073   \n",
       "\n",
       "                          diff  \n",
       "level id                        \n",
       "1     CA              0.000002  \n",
       "3     HOBBIES         0.000004  \n",
       "      HOUSEHOLD       0.000005  \n",
       "4     FOODS_1         0.000002  \n",
       "      FOODS_2         0.000004  \n",
       "      HOBBIES_1       0.000004  \n",
       "      HOUSEHOLD_1     0.000002  \n",
       "      HOUSEHOLD_2     0.000003  \n",
       "5     CA_HOBBIES      0.000003  \n",
       "      CA_HOUSEHOLD    0.000004  \n",
       "      TX_HOUSEHOLD    0.000001  \n",
       "      WI_HOBBIES      0.000001  \n",
       "6     CA_FOODS_2      0.000001  \n",
       "      CA_HOBBIES_1    0.000003  \n",
       "      CA_HOUSEHOLD_1  0.000002  \n",
       "      CA_HOUSEHOLD_2  0.000002  \n",
       "      TX_FOODS_1      0.000001  \n",
       "      WI_FOODS_2      0.000002  \n",
       "      WI_HOBBIES_1    0.000001  \n",
       "7     CA_2_HOUSEHOLD  0.000001  \n",
       "      CA_3_HOUSEHOLD  0.000001  \n",
       "8     WI_2_FOODS_2    0.000001  \n",
       "9     FOODS_2_029     0.000001  \n",
       "      FOODS_2_183     0.000001  \n",
       "      FOODS_3_586     0.000001  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## de weights worden ook vergeleken met de weights die zijn vrijgegeven om te kijken of we dichtbij zitten\n",
    "\n",
    "\n",
    "# Predicted weights\n",
    "W_df = pd.DataFrame(W,index = roll_index,columns=['w'])\n",
    "\n",
    "# Load the original weights:\n",
    "W_original_df = pd.read_csv(data_dir+'weights_validation.csv')\n",
    "\n",
    "# Set new index, calculate difference between original and predicted:\n",
    "W_original_df = W_original_df.set_index(W_df.index)\n",
    "W_original_df['Predicted'] = W_df.w\n",
    "W_original_df['diff'] = W_original_df.Weight - W_original_df.Predicted\n",
    "\n",
    "# See where we are off by more than e-6\n",
    "m = W_original_df.Weight.values - W_df.w.values > 0.000001\n",
    "W_original_df[m]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW = W/np.sqrt(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_df = pd.DataFrame(np.stack((S, W, SW), axis=-1),index = roll_index,columns=['s','w','sw'])\n",
    "sw_df.to_pickle('sw_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollup(v):\n",
    "    '''\n",
    "    v - np.array of size (30490 rows, n day columns)\n",
    "    v_rolledup - array of size (n, 42840)\n",
    "    '''\n",
    "    return roll_mat_csr * v #(v.T*roll_mat_csr.T).T\n",
    "\n",
    "def rollup_loss(v):\n",
    "    \n",
    "    intermediate = roll_mat_csr * K.eval(v)\n",
    "    \n",
    "    return tf.convert_to_tensor(intermediate)\n",
    "# Function to calculate WRMSSE:\n",
    "def wrmsse(preds, y_true, score_only=False, s = S, w = W, sw=SW):\n",
    "    '''\n",
    "    preds - Predictions: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    y_true - True values: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    sequence_length - np.array of size (42840,)\n",
    "    sales_weight - sales weights based on last 28 days: np.array (42840,)\n",
    "    '''\n",
    "    \n",
    "    if score_only:\n",
    "        return np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(rollup(preds.values-y_true.values))\n",
    "                            ,axis=1)) * sw)/12 #<-used to be mistake here\n",
    "    else: \n",
    "        score_matrix = (np.square(rollup(preds.values-y_true.values)) * np.square(w)[:, None])/ s[:, None]\n",
    "        score = np.sum(np.sqrt(np.mean(score_matrix,axis=1)))/12 #<-used to be mistake here\n",
    "        return score, score_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fold pass here:\n",
    "file_pass = './'# '/kaggle/input/fast-wrmsse-and-sw-frame/'\n",
    "\n",
    "# Load S and W weights for WRMSSE calcualtions:\n",
    "sw_df = pd.read_pickle(file_pass+'sw_df.pkl')\n",
    "S = sw_df.s.values\n",
    "W = sw_df.w.values\n",
    "SW = sw_df.sw.values\n",
    "\n",
    "# Load roll up matrix to calcualte aggreagates:\n",
    "roll_mat_df = pd.read_pickle(file_pass+'roll_mat_df.pkl')\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "del roll_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions:\n",
    "sub = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "sub = sub[sub.id.str.endswith('validation')]\n",
    "sub.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "DAYS_PRED = sub.shape[1]    # 28\n",
    "\n",
    "# Ground truth:\n",
    "dayCols = [\"d_{}\".format(i) for i in range(1914-DAYS_PRED, 1914)]\n",
    "y_true = sales[dayCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 100 -r 5\n",
    "# # n - execute the statement n times \n",
    "# # r - repeat each loop r times and return the best\n",
    "\n",
    "score = wrmsse(sub, y_true, score_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5737902294863195"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_sales = reduce_mem_usage(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data, for now it only contains the sales and no extra features\n",
    "sales = train_sales.drop([\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1).T\n",
    "\n",
    "# normalize\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(sales)\n",
    "sales = scaler.transform(sales)\n",
    "sales = pd.DataFrame(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo().astype(np.float32)\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll_mat_csr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tensor = convert_sparse_matrix_to_sparse_tensor(roll_mat_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "timesteps = 28\n",
    "prediction_steps = 1\n",
    "len_window = timesteps + prediction_steps\n",
    "\n",
    "nr_training_days = sales.shape[0]\n",
    "nr_sets = nr_training_days - len_window + 1\n",
    "\n",
    "base, predictions = [], []\n",
    "\n",
    "for i in range(nr_sets):\n",
    "    samples = sales.iloc[i:i+timesteps]\n",
    "    pred = sales.iloc[i+timesteps]\n",
    "    base.append(samples.to_numpy())\n",
    "    predictions.append(pred.to_numpy())\n",
    "    \n",
    "X = np.array(base)\n",
    "y = np.array(predictions)\n",
    "\n",
    "del base, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor = 0.1, patience = 2 , verbose = 1, mode= 'min', min_lr = 0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rollup_loss(v):\n",
    "\n",
    "#     intermediate = sparse_tensor * v\n",
    "    intermediate = tf.sparse.sparse_dense_matmul(sparse_tensor,tf.transpose(v))\n",
    "    return intermediate\n",
    "\n",
    "# Function to calculate WRMSSE during training:\n",
    "# make sure that s = S, w = W, sw=SW) are available\n",
    "def wrmsse_loss(y_true, y_pred):\n",
    "    '''\n",
    "    preds - Predictions: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    y_true - True values: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    sequence_length - np.array of size (42840,)\n",
    "    sales_weight - sales weights based on last 28 days: np.array (42840,)\n",
    "    '''\n",
    "        \n",
    "#     return K.sum(root_mean_squared_scaled_error(y_true,y_pred) * SW)  / 12 \n",
    "\n",
    "    return K.sum(\n",
    "            K.sqrt(\n",
    "                K.mean(\n",
    "                    K.square(rollup_loss(y_pred-y_true))\n",
    "                        ,axis=1)) * SW)/12 #<-used to be mistake here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_scaled_error(y_true,y_pred):\n",
    "    \n",
    "    sample_length = 28 ## 28 historical days ..\n",
    "    forecasting_horizon = 1 ## we are predicting 1 day...\n",
    "    upper_bound = sample_length + forecasting_horizon\n",
    "    lower_bound = sample_length + 1 - 1\n",
    "    numerator =  K.sum(K.square(y_true[lower_bound:upper_bound]-y_pred[lower_bound:upper_bound]))\n",
    "    lower_bound = 2 - 1\n",
    "    ## normally we would only count the denominator starting when the product is actively sold\n",
    "    ## I don't see how we can achieve that so I did not do it.\n",
    "    denominator = (1/(sample_length - 1 )) * K.sum(K.square(y_true[lower_bound:sample_length] - y_true[lower_bound-1:sample_length-1]))\n",
    "    value_to_be_sqrt = (1/forecasting_horizon) * (numerator/denominator)\n",
    "    result = K.sqrt(value_to_be_sqrt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True, input_shape=(timesteps, n_features))))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "model.add(Dense(30490))\n",
    "model.compile(optimizer='adam', loss=wrmsse_loss, metrics=['mse'])\n",
    "\n",
    "# callbacks=[WandbCallback(data_type=\"image\", validation_data=(X_test, y_test), labels=character_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=10, callbacks=[reduce_lr], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "\n",
    "for i in range(28):    \n",
    "    # get input for prediction by selecting last 28 days from sales\n",
    "    X_pred = []\n",
    "    X_pred.append(sales.iloc[-timesteps:].to_numpy())\n",
    "    X_pred = np.array(X_pred)\n",
    "    \n",
    "    # get prediction\n",
    "    prediction = model.predict(X_pred)\n",
    "    # add prediction to sales so that it can be used for next prediction\n",
    "    sales.loc[sales.shape[0]] = prediction[0]\n",
    "    \n",
    "predictions = sales.iloc[-28:]\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions = np.round(np.abs(predictions))\n",
    "predictions = pd.DataFrame(predictions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "predictions_copy = predictions\n",
    "final_submission = pd.concat([predictions, predictions_copy])\n",
    "final_submission.reset_index(drop=True, inplace=True)\n",
    "final_submission = final_submission.astype(int)\n",
    "final_submission.insert(0, 'id', submission_file['id'])\n",
    "final_submission.columns = ['id'] + [f\"F{i}\" for i in range(1, 29)]\n",
    "\n",
    "final_submission.to_csv('submission_wrmsse.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
