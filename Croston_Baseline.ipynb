{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/siavrez/simple-eda-with-croston-method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "sell_prices = pd.read_csv('sell_prices.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "sales_train_validation = pd.read_csv('sales_train_validation.csv')\n",
    "\n",
    "# load sample submission\n",
    "sample_subm = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/croston-forecast-model-for-intermittent-demand-360287a17f5f\n",
    "def Croston(ts, extra_periods, alpha):\n",
    "    d = np.array(ts) # Transform the input into a numpy array\n",
    "    cols = len(d) # Historical period length\n",
    "    d = np.append(d,[np.nan]*extra_periods) # Append np.nan into the demand array to cover future periods\n",
    "    \n",
    "    #level (a), periodicity(p) and forecast (f)\n",
    "    a,p,f = np.full((3,cols+extra_periods),np.nan)\n",
    "    q = 1 #periods since last demand observation\n",
    "    \n",
    "    # Initialization\n",
    "    first_occurence = np.argmax(d[:cols]>0)\n",
    "    a[0] = d[first_occurence]\n",
    "    p[0] = 1 + first_occurence\n",
    "    f[0] = a[0]/p[0]\n",
    "    # Create all the t+1 forecasts\n",
    "    for t in range(0,cols):        \n",
    "        if d[t] > 0:\n",
    "            a[t+1] = alpha*d[t] + (1-alpha)*a[t] \n",
    "            p[t+1] = alpha*q + (1-alpha)*p[t]\n",
    "            f[t+1] = a[t+1]/p[t+1]\n",
    "            q = 1           \n",
    "        else:\n",
    "            a[t+1] = a[t]\n",
    "            p[t+1] = p[t]\n",
    "            f[t+1] = f[t]\n",
    "            q += 1\n",
    "       \n",
    "    # Future Forecast \n",
    "    a[cols+1:cols+extra_periods] = a[cols]\n",
    "    p[cols+1:cols+extra_periods] = p[cols]\n",
    "    f[cols+1:cols+extra_periods] = f[cols]\n",
    "                      \n",
    "    df = pd.DataFrame.from_dict({\"Demand\":d,\"Forecast\":f,\"Period\":p,\"Level\":a,\"Error\":d-f})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = range(1, 1914)\n",
    "time_series_columns = [f'd_{i}' for i in days]\n",
    "time_series_data = sales_train_validation[time_series_columns]\n",
    "\n",
    "forecast_ = time_series_data.apply(lambda x : Croston(x, extra_periods=28, alpha=0.1)['Forecast'].tail(28), axis=1)\n",
    "\n",
    "cols = ['F'+str(i+1) for i in range(28)]\n",
    "forecast_.columns = cols\n",
    "\n",
    "validation_ids = sales_train_validation['id'].values\n",
    "evaluation_ids = [i.replace('validation', 'evaluation') for i in validation_ids]\n",
    "ids = np.concatenate([validation_ids, evaluation_ids])\n",
    "predictions = pd.DataFrame(ids, columns=['id'])\n",
    "forecast = pd.concat([forecast_] * 2).reset_index(drop=True)\n",
    "predictions = pd.concat([predictions, forecast], axis=1)\n",
    "predictions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
