{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data (for now, sell_prices & calendar are not used)\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "train_sales = pd.read_csv(data_dir + 'sales_train_validation.csv')\n",
    "#sell_prices = pd.read_csv(data_dir + 'sell_prices.csv')\n",
    "#calendar = pd.read_csv(data_dir + 'calendar.csv')\n",
    "submission_file = pd.read_csv(data_dir + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  d_9  d_10  ...  d_1904  d_1905  \\\n",
       "0    0    0    0    0    0    0    0    0    0     0  ...       1       3   \n",
       "1    0    0    0    0    0    0    0    0    0     0  ...       0       0   \n",
       "2    0    0    0    0    0    0    0    0    0     0  ...       2       1   \n",
       "3    0    0    0    0    0    0    0    0    0     0  ...       1       0   \n",
       "4    0    0    0    0    0    0    0    0    0     0  ...       2       1   \n",
       "\n",
       "   d_1906  d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       0       1       1       1       3       0       1       1  \n",
       "1       0       0       0       1       0       0       0       0  \n",
       "2       2       1       1       1       0       1       1       1  \n",
       "3       5       4       1       0       1       3       7       2  \n",
       "4       1       0       1       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1913 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training data, for now it only contains the sales and no extra features\n",
    "sales = train_sales.drop([\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "# if you want to use all data, use start_day = 1\n",
    "\n",
    "# because of memory issues, only use data from last year for now\n",
    "start_day = 1913 - 365\n",
    "\n",
    "timesteps = 14\n",
    "prediction_steps = 28\n",
    "len_window = timesteps + prediction_steps\n",
    "\n",
    "nr_training_days = sales.shape[1] - start_day + 1\n",
    "nr_sets = nr_training_days - len_window + 1\n",
    "\n",
    "base, predictions = [], []\n",
    "\n",
    "for i in range(nr_sets):\n",
    "    if (start_day != 1):\n",
    "        i = i + start_day - 1\n",
    "    samples = sales.iloc[:, i:i+timesteps]\n",
    "    preds = sales.iloc[:,i+timesteps:i+len_window]\n",
    "    base.extend(samples.to_numpy())\n",
    "    predictions.extend(preds.to_numpy())\n",
    "    \n",
    "base = np.array(base)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu bestaat samples uit groepen van 14 opeenvolgende dagen, en predictions uit groepen van de 28 dagen erna. Dus het model leert de sales, voor alle producten, per 4 weken te voorspellen op basis van de sales van de 2 weken daarvoor. Kunnen ook proberen om per week te voorspellen, en dan de voorspellingen mee te nemen als input voor de volgende voorspelling. Of zelfs per dag.\n",
    "\n",
    "Elke sample in de for-loop in de cell hierboven bevat de sales voor alle 30490 items van 14 opeenvolgende dagen. Omdat dus voor alle 30490 items tegelijk wordt voorspeld, kunnen we denk ik geen features toevoegen die iets over een item zeggen (zoals sell price, store, state, category etc), maar we kunnen wel features toevoegen die iets zeggen over een dag (zoals event, snap, month etc). Wat wel kan is voor ieder item een apart model trainen, 30490 models dus haha, maar dat lijkt me niet doable. Zouden misschien wel bijv per store een model kunnen trainen.\n",
    "\n",
    "De sliding window werkt hier nu wel goed. Probleem is alleen dat er heel erg veel data komt, wat leidt tot memory errors. Als je alleen de sales van het laatste jaar in de data pakt (wat nu ook in de cell hierboven gebeurt), duurt het trainen van het model ongeveer al 2 uur.\n",
    "\n",
    "start_day=1913-365, timesteps=14, prediction_steps=28 leidt tot score in kaggle van 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize & reshape data\n",
    "\n",
    "input_scaler = MinMaxScaler()\n",
    "output_scaler = StandardScaler()\n",
    "\n",
    "input_scaler.fit(base)\n",
    "X = input_scaler.transform(base)\n",
    "\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "output_scaler.fit(predictions)\n",
    "y = output_scaler.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True, input_shape=(timesteps, n_features))))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "model.add(Dense(prediction_steps))\n",
    "model.compile(optimizer='adam', loss='mse') # note that loss is not competition loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "9909250/9909250 [==============================] - 4123s 416us/step - loss: 0.4243\n",
      "Epoch 2/2\n",
      "9909250/9909250 [==============================] - 4121s 416us/step - loss: 0.4109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x239e196a6c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "model.fit(X, y, epochs=2, verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM model is gemaakt en getrained. Nu nog predicten en submission maken. Omdat het model getrained is om 4 weken sales te voorspellen uit 2 weken daarvoor, wordt X_pred de laatste 2 weken van de data.\n",
    "\n",
    "Also note: voorspellingen worden gedaan voor 'validation' (dus eerste 28 dagen na data in train). die voorspellingen worden direct gekopieerd naar 'evaluation' (28 dagen na validation), dus dat slaat nergens op. maar is niet erg want public leaderboard is alleen gebaseerd op validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input data for predictions\n",
    "\n",
    "X_pred = sales.iloc[:,-timesteps:].to_numpy()\n",
    "\n",
    "# reshape & normalize\n",
    "X_pred = X_pred.reshape((len(sales), X_pred.shape[1]))\n",
    "X_pred = input_scaler.transform(X_pred)\n",
    "X_pred = X_pred.reshape((len(sales), X_pred.shape[1], 1))\n",
    "\n",
    "# get predictions\n",
    "norm_pred = model.predict(X_pred)\n",
    "predictions = output_scaler.inverse_transform(norm_pred)\n",
    "predictions = np.round(np.abs(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "\n",
    "validation = pd.concat([pd.DataFrame(predictions[:,0:prediction_steps]), pd.DataFrame(predictions[:,-prediction_steps:])])\n",
    "validation = validation.astype(int)\n",
    "\n",
    "validation.reset_index(inplace=True, drop=True)\n",
    "\n",
    "validation['id'] = submission_file.id\n",
    "validation = validation.reindex(columns=['id'] + [c for c in validation.columns if c != 'id'], copy=False)\n",
    "\n",
    "validation.columns = ['id'] + [f\"F{i}\" for i in range(1, 29)]\n",
    "\n",
    "validation.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
