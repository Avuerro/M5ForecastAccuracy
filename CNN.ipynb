{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Bidirectional, Input, Flatten \n",
    "from keras.layers.core import Reshape\n",
    "\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data (for now, sell_prices & calendar are not used)\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "train_sales = pd.read_csv(data_dir + 'sales_train_validation.csv')\n",
    "sell_prices = pd.read_csv(data_dir + 'sell_prices.csv')\n",
    "calendar = pd.read_csv(data_dir + 'calendar.csv')\n",
    "submission_file = pd.read_csv(data_dir + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It might be interesting to train each LSTM on each store..\n",
    "train_sales['store_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales[train_sales['cat_id'] == \"HOBBIES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ik vroeg me af hoeveel categorien er zijn\n",
    "train_sales['cat_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ik wilde het indexeren op basis van kolom waardes proberen.\n",
    "sell_prices[sell_prices['item_id'] == 'HOBBIES_1_001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## voorbeelden events\n",
    "calendar[(calendar['event_name_1'].notna() == True) & (calendar['event_name_1'] == 'Ramadan starts')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nog een voorbeeld\n",
    "calendar[(calendar['event_name_1'].notna() == True) & (calendar['event_name_1'] == 'ValentinesDay')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Im thinking of two things that might be interesting to implement. The first is the event type on a certain day. If we can train a CNN to learn the relation between a day and the events. Then we could use that information in the LSTM. I was also thinking about product prices, maybe we can train the CNN on days and product prices.\n",
    "\n",
    "I think it would also be interesting to train the CNN on the relation between events and prices.\n",
    "\n",
    "I'm going to try to train the CNN on the relation between events and item prices. \n",
    "\n",
    "The dataset would consist of \n",
    "day, wm_yr_wk, item_id,  event , sell_price\n",
    "\n",
    "the input for the CNN would be\n",
    "X = day,wm_yr_wk, item_id, event\n",
    "Y = sell_price\n",
    "\n",
    "We first train the CNN to predict the sell prices, the goal is to learn the relation between events and sell prices\n",
    "\n",
    "\n",
    "Then the next step is combine the CNN with the LSTM. So we would create a new model, which starts with CNN and ends with LSTM. The CNN is the same as the previous CNN however we remove the last layer, the prediction layer, and continue on to the LSTM. \n",
    "\n",
    "The input would be \n",
    "X = day, wm_yr_wk, item_id,  event \n",
    "Y = number_of_sales\n",
    "\n",
    "The goal is that this time the LSTM uses information about the relation of event and sell price when predicting number of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset...\n",
    "#onderstaande is uiteindelijk niet meer nodig\n",
    "# new_dataset = pd.concat([calendar,sell_prices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sales =train_sales.drop([ \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales and Event\n",
    "the first data set will represent days, sales, events\n",
    "thus 1913, 30490,1913 --> maybe better as follows rows 1913, columns 304901 where the first 30490 columns \n",
    "are item sales and the last column indicates whether that day was an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sales_v2 = modified_sales.drop(['id','item_id'], axis=1).T\n",
    "modified_sales_v2['event_name_1'] = calendar[:1913]['event_name_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sales_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to deal with the NaNs as well as the event_name_1 .. maybe we can just use 0 and 1 to indicate that there was an event. However this would mean that you neglect the available information between event type and products which is quite important. Therefore it might be interesting to use one hot encodings ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sales_v2[modified_sales_v2['event_name_1'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sales_v2['event_name_1'].fillna('none', inplace=True)\n",
    "\n",
    "numerical_event_values =  np.arange(modified_sales_v2['event_name_1'].unique().shape[0])\n",
    "numerical_event_values = [str(x ) for x in numerical_event_values]\n",
    "event_array = np.column_stack((modified_sales_v2['event_name_1'].unique(), \\\n",
    "                        numerical_event_values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_dict = {key: value for (key, value) in zip(modified_sales_v2['event_name_1'].unique(), \\\n",
    "                        numerical_event_values)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "encoded = to_categorical(numerical_event_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sales_v2['event_name_1'].iloc[1912]\n",
    "event_dict['none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uiteindelijk dus geen gebruik gemaakt van one hot encoding omdat het Model klaagt omdat de kolom een lijst bevat ipv numerieke waardes\n",
    "for i in range(1913):\n",
    "    event = modified_sales_v2['event_name_1'].iloc[i]\n",
    "    index = int(event_dict[event])\n",
    "    modified_sales_v2['event_name_1'].iloc[i] = index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "timesteps = 28\n",
    "prediction_steps = 1\n",
    "len_window = timesteps + prediction_steps\n",
    "\n",
    "nr_training_days = modified_sales_v2.shape[0]\n",
    "nr_sets = nr_training_days - len_window + 1\n",
    "\n",
    "base, predictions = [], []\n",
    "\n",
    "for i in range(nr_sets):\n",
    "    samples = modified_sales_v2.iloc[i:i+timesteps]\n",
    "    pred = modified_sales_v2.iloc[i+timesteps]\n",
    "    base.append(samples.to_numpy())\n",
    "    predictions.append(pred.to_numpy())\n",
    "    \n",
    "X = np.array(base)\n",
    "y = np.array(predictions)\n",
    "\n",
    "del base, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ik twijfel nog over dat one hot encoding van de events.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "We kunnen eerst een 1D conv laag proberen in [dit artikel](https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/) staat op interessante info over hoe je meerdere cnns kunt combineren. Misschien kunnen wij dat ook doen, dus meerdere CNNs en dan de output van alle3 als input gebruiken voor de LSTM. De output shape moet dan wel passen op de input shape van de LSTM.\n",
    "\n",
    "Maar eerst kunnen we een 1D Conv laag proberen.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 30491\n",
    "visible1 = Input(shape=(timesteps, n_features))\n",
    "print(visible1.shape)\n",
    "cnn1 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible1)\n",
    "print(cnn1.shape)\n",
    "cnn1 = MaxPooling1D(pool_size=14)(cnn1)\n",
    "print(cnn1.shape)\n",
    "dense = Dense(50, activation='relu')(cnn1)\n",
    "print(dense.shape[1])\n",
    "output = Dense(30491)(dense)\n",
    "print(output.shape)\n",
    "reshaped_output = Reshape((output.shape[2], output.shape[1]))(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=visible1, outputs=reshaped_output)\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y.reshape(1885,30491,1) , batch_size=32, epochs=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het netwerk traint nu wel maar de loss is erg hoog. Ik moet nog even kijken of dit gewoon een kweste van lagen teovoegen is, of dat er iets anders aan de hand is. Ik gebruik nu ook geen one hot encoding voor de evenementen omdat Keras dan begint te klagen dat er iets mis is met de data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple LSTMS\n",
    "\n",
    "Ik bekeek de data en toen zag ik dat de 30490 items niet unieke producten zijn. Het zijn dezelfde producten maar dan over verschillende stores. Misschien is het interessant om per store een LSTM te trainen. Dan heb je veel minder features per LSTM. Vervolgens kun je tijdens het predicten per item bepalen welk LSTM je moet gebruiken omdat **id** een combinatie is van **item_id**, **dept_id** en **store_id**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales and ItemPrices\n",
    "The second dataset will represent days, sales and item prices. \n",
    "This dataset is a bit more trickier since we have 30490 item sales and 30490 item prices so the result would be something like\n",
    "\n",
    "1913 rows (days)\n",
    "each column would ideally represent number_of_sales, price\n",
    "I think the end result would be something along the lines of\n",
    "\n",
    "1913,30490,2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
