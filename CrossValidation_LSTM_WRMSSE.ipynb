{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "\n",
    "## reload scripts before executing them\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset.reduce_memory import reduce_mem_usage\n",
    "\n",
    "from dataset.create_windows import create_windows\n",
    "from dataset.create_submission import create_submission_csv\n",
    "\n",
    "from evaluation.rmsse_loss import root_mean_squared_scaled_error\n",
    "\n",
    "from train.cross_validate import cross_validate\n",
    "\n",
    "from models.lstm import lstm_model\n",
    "\n",
    "\n",
    "from evaluation.wrmsse_loss import WRMSSE_Loss\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/whydoihavetoregister/m5_accuracy_forecasting\" target=\"_blank\">https://app.wandb.ai/whydoihavetoregister/m5_accuracy_forecasting</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/whydoihavetoregister/m5_accuracy_forecasting/runs/3uvp79ev\" target=\"_blank\">https://app.wandb.ai/whydoihavetoregister/m5_accuracy_forecasting/runs/3uvp79ev</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/whydoihavetoregister/m5_accuracy_forecasting/runs/3uvp79ev"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Init Weights and Biases\n",
    "\n",
    "wandb.init(sync_tensorboard=True, entity=\"whydoihavetoregister\", project=\"m5_accuracy_forecasting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "train_sales = pd.read_csv(data_dir + 'sales_train_validation.csv')\n",
    "#sell_prices = pd.read_csv(data_dir + 'sell_prices.csv')\n",
    "calendar = pd.read_csv(data_dir + 'calendar.csv')\n",
    "submission_file = pd.read_csv(data_dir + 'sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_sales = reduce_mem_usage(train_sales) # takes about 4mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "sales = train_sales.drop([\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1).T\n",
    "\n",
    "# normalize\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(sales)\n",
    "sales = scaler.transform(sales)\n",
    "sales = pd.DataFrame(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pass = './'\n",
    "\n",
    "# Load S and W weights for WRMSSE calcualtions:\n",
    "sw_df = pd.read_pickle(file_pass+'sw_df.pkl')\n",
    "S = sw_df.s.values\n",
    "W = sw_df.w.values\n",
    "SW = sw_df.sw.values\n",
    "\n",
    "# Load roll up matrix to calcualte aggreagates:\n",
    "roll_mat_df = pd.read_pickle(file_pass+'roll_mat_df.pkl')\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "del roll_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "timesteps = 28\n",
    "prediction_steps = 1\n",
    "\n",
    "X,y = create_windows(sales, timesteps,prediction_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRMSSE_Loss = WRMSSE_Loss(SW,roll_mat_csr)\n",
    "wrmsse_loss_method = WRMSSE_Loss.wrmsse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor = 0.1, patience = 2 , verbose = 1, mode= 'min', min_lr = 0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = lstm_model(timesteps,n_features,loss=wrmsse_loss_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "315/315 [==============================] - 20s 63ms/step - loss: 0.1062 - mse: 0.0144\n",
      "Epoch 2/15\n",
      "315/315 [==============================] - 11s 36ms/step - loss: 0.0591 - mse: 0.0130\n",
      "Epoch 3/15\n",
      "315/315 [==============================] - 12s 39ms/step - loss: 0.0495 - mse: 0.0123\n",
      "Epoch 4/15\n",
      "315/315 [==============================] - 12s 39ms/step - loss: 0.0452 - mse: 0.0117\n",
      "Epoch 5/15\n",
      "315/315 [==============================] - 12s 38ms/step - loss: 0.0444 - mse: 0.0113\n",
      "Epoch 6/15\n",
      "315/315 [==============================] - 11s 34ms/step - loss: 0.0421 - mse: 0.0110\n",
      "Epoch 7/15\n",
      "315/315 [==============================] - 11s 34ms/step - loss: 0.0400 - mse: 0.0108\n",
      "Epoch 8/15\n",
      "315/315 [==============================] - 11s 34ms/step - loss: 0.0395 - mse: 0.0106\n",
      "Epoch 9/15\n",
      "315/315 [==============================] - 11s 35ms/step - loss: 0.0384 - mse: 0.0104\n",
      "Epoch 10/15\n",
      "315/315 [==============================] - 11s 34ms/step - loss: 0.0379 - mse: 0.0102\n",
      "Epoch 11/15\n",
      "315/315 [==============================] - 11s 34ms/step - loss: 0.0366 - mse: 0.0101\n",
      "Epoch 12/15\n",
      "315/315 [==============================] - 11s 34ms/step - loss: 0.0352 - mse: 0.0100\n",
      "Epoch 13/15\n",
      "315/315 [==============================] - 11s 36ms/step - loss: 0.0338 - mse: 0.0099\n",
      "Epoch 14/15\n",
      "315/315 [==============================] - 11s 35ms/step - loss: 0.0318 - mse: 0.0098\n",
      "Epoch 15/15\n",
      "315/315 [==============================] - 11s 34ms/step - loss: 0.0301 - mse: 0.0097\n",
      "314/314 [==============================] - 12s 37ms/step\n",
      "loss: 0.05610%\n",
      "Epoch 1/15\n",
      "629/629 [==============================] - 32s 51ms/step - loss: 0.0405 - mse: 0.0114\n",
      "Epoch 2/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0353 - mse: 0.0111\n",
      "Epoch 3/15\n",
      "629/629 [==============================] - 21s 34ms/step - loss: 0.0331 - mse: 0.0110\n",
      "Epoch 4/15\n",
      "629/629 [==============================] - 21s 34ms/step - loss: 0.0311 - mse: 0.0109\n",
      "Epoch 5/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0305 - mse: 0.0108\n",
      "Epoch 6/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0296 - mse: 0.0108\n",
      "Epoch 7/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0297 - mse: 0.0107\n",
      "Epoch 8/15\n",
      "629/629 [==============================] - 22s 34ms/step - loss: 0.0294 - mse: 0.0107\n",
      "Epoch 9/15\n",
      "629/629 [==============================] - 21s 34ms/step - loss: 0.0285 - mse: 0.0106\n",
      "Epoch 10/15\n",
      "629/629 [==============================] - 22s 34ms/step - loss: 0.0277 - mse: 0.0106\n",
      "Epoch 11/15\n",
      "629/629 [==============================] - 21s 34ms/step - loss: 0.0274 - mse: 0.0106\n",
      "Epoch 12/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0271 - mse: 0.0105\n",
      "Epoch 13/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0271 - mse: 0.0105\n",
      "Epoch 14/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0267 - mse: 0.0105\n",
      "Epoch 15/15\n",
      "629/629 [==============================] - 22s 35ms/step - loss: 0.0266 - mse: 0.0105\n",
      "314/314 [==============================] - 13s 40ms/step\n",
      "loss: 0.05418%\n",
      "Epoch 1/15\n",
      "943/943 [==============================] - 48s 51ms/step - loss: 0.0365 - mse: 0.0118\n",
      "Epoch 2/15\n",
      "943/943 [==============================] - 32s 34ms/step - loss: 0.0329 - mse: 0.0116\n",
      "Epoch 3/15\n",
      "943/943 [==============================] - 32s 34ms/step - loss: 0.0318 - mse: 0.0115\n",
      "Epoch 4/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0310 - mse: 0.0115\n",
      "Epoch 5/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0304 - mse: 0.0114\n",
      "Epoch 6/15\n",
      "943/943 [==============================] - 32s 34ms/step - loss: 0.0304 - mse: 0.0114\n",
      "Epoch 7/15\n",
      "943/943 [==============================] - 32s 34ms/step - loss: 0.0298 - mse: 0.0113\n",
      "Epoch 8/15\n",
      "943/943 [==============================] - 32s 33ms/step - loss: 0.0297 - mse: 0.0113\n",
      "Epoch 9/15\n",
      "943/943 [==============================] - 32s 34ms/step - loss: 0.0292 - mse: 0.0113\n",
      "Epoch 10/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0289 - mse: 0.0112\n",
      "Epoch 11/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0288 - mse: 0.0112\n",
      "Epoch 12/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0287 - mse: 0.0112\n",
      "Epoch 13/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0287 - mse: 0.0112\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0278 - mse: 0.0111\n",
      "Epoch 15/15\n",
      "943/943 [==============================] - 31s 33ms/step - loss: 0.0276 - mse: 0.0111\n",
      "314/314 [==============================] - 12s 39ms/step\n",
      "loss: 0.05290%\n",
      "Epoch 1/15\n",
      "1257/1257 [==============================] - 65s 51ms/step - loss: 0.0352 - mse: 0.0123\n",
      "Epoch 2/15\n",
      "1257/1257 [==============================] - 56s 45ms/step - loss: 0.0335 - mse: 0.0122\n",
      "Epoch 3/15\n",
      "1257/1257 [==============================] - 45s 35ms/step - loss: 0.0326 - mse: 0.0122\n",
      "Epoch 4/15\n",
      "1257/1257 [==============================] - 42s 34ms/step - loss: 0.0321 - mse: 0.0122\n",
      "Epoch 5/15\n",
      "1257/1257 [==============================] - 43s 34ms/step - loss: 0.0317 - mse: 0.0121\n",
      "Epoch 6/15\n",
      "1257/1257 [==============================] - 42s 33ms/step - loss: 0.0313 - mse: 0.0121\n",
      "Epoch 7/15\n",
      "1257/1257 [==============================] - 42s 34ms/step - loss: 0.0311 - mse: 0.0121\n",
      "Epoch 8/15\n",
      "1257/1257 [==============================] - 42s 34ms/step - loss: 0.0308 - mse: 0.0121\n",
      "Epoch 9/15\n",
      "1257/1257 [==============================] - 42s 34ms/step - loss: 0.0307 - mse: 0.0121\n",
      "Epoch 10/15\n",
      "1257/1257 [==============================] - 41s 33ms/step - loss: 0.0305 - mse: 0.0121\n",
      "Epoch 11/15\n",
      "1257/1257 [==============================] - 41s 33ms/step - loss: 0.0304 - mse: 0.0121\n",
      "Epoch 12/15\n",
      "1257/1257 [==============================] - 41s 33ms/step - loss: 0.0303 - mse: 0.0121\n",
      "Epoch 13/15\n",
      "1257/1257 [==============================] - 41s 33ms/step - loss: 0.0302 - mse: 0.0121\n",
      "Epoch 14/15\n",
      "1257/1257 [==============================] - 41s 33ms/step - loss: 0.0301 - mse: 0.0120\n",
      "Epoch 15/15\n",
      "1257/1257 [==============================] - 42s 33ms/step - loss: 0.0299 - mse: 0.0120\n",
      "314/314 [==============================] - 160s 511ms/step\n",
      "loss: 0.05797%\n",
      "Epoch 1/15\n",
      "1571/1571 [==============================] - 164s 104ms/step - loss: 0.0372 - mse: 0.0132\n",
      "Epoch 2/15\n",
      "1571/1571 [==============================] - 84s 53ms/step - loss: 0.0354 - mse: 0.0131\n",
      "Epoch 3/15\n",
      "1571/1571 [==============================] - 79s 50ms/step - loss: 0.0343 - mse: 0.0131\n",
      "Epoch 4/15\n",
      "1571/1571 [==============================] - 74s 47ms/step - loss: 0.0338 - mse: 0.0130\n",
      "Epoch 5/15\n",
      "1571/1571 [==============================] - 66s 42ms/step - loss: 0.0332 - mse: 0.0130\n",
      "Epoch 6/15\n",
      "1571/1571 [==============================] - 57s 36ms/step - loss: 0.0329 - mse: 0.0130\n",
      "Epoch 7/15\n",
      "1571/1571 [==============================] - 53s 34ms/step - loss: 0.0327 - mse: 0.0130\n",
      "Epoch 8/15\n",
      "1571/1571 [==============================] - 55s 35ms/step - loss: 0.0324 - mse: 0.0130\n",
      "Epoch 9/15\n",
      "1571/1571 [==============================] - 52s 33ms/step - loss: 0.0323 - mse: 0.0129\n",
      "Epoch 10/15\n",
      "1571/1571 [==============================] - 54s 34ms/step - loss: 0.0321 - mse: 0.0129\n",
      "Epoch 11/15\n",
      "1571/1571 [==============================] - 54s 34ms/step - loss: 0.0320 - mse: 0.0129\n",
      "Epoch 12/15\n",
      "1571/1571 [==============================] - 55s 35ms/step - loss: 0.0318 - mse: 0.0129\n",
      "Epoch 13/15\n",
      "1571/1571 [==============================] - 55s 35ms/step - loss: 0.0318 - mse: 0.0129\n",
      "Epoch 14/15\n",
      "1571/1571 [==============================] - 54s 34ms/step - loss: 0.0317 - mse: 0.0129\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/15\n",
      "1571/1571 [==============================] - 52s 33ms/step - loss: 0.0314 - mse: 0.0129\n",
      "314/314 [==============================] - 232s 740ms/step\n",
      "loss: 0.06455%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.05609799484918072,\n",
       "  0.054176644250086156,\n",
       "  0.052902900346904806,\n",
       "  0.05797216827702371,\n",
       "  0.06454920930087946],\n",
       " 0.05713978340481497,\n",
       " 0.00408433964738724)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(lstm_model,X,y,batch_size=32,epochs = 15, number_of_folds = 5,callbacks =[reduce_lr,WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
